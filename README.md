# Kahoot Clone - Production-Ready Microservices Platform

> ** Professional Modular Infrastructure - DEPLOYED**
> - **Infrastructure**: `infrastructure/` - Modular Terraform + Role-based Ansible
> - **Region**: AWS us-east-1
> - **Deploy**: `.\infrastructure\deploy.ps1 -Action all`
> - **Status**: Jenkins Pipeline Active with GitHub Webhook Integration

[![Production Ready](https://img.shields.io/badge/Production-Ready-green.svg)](https://github.com/yourusername/kahoot-clone)
[![K8s](https://img.shields.io/badge/K8s-3%20Nodes-blue.svg)](https://kubernetes.io/)
[![Test Coverage](https://img.shields.io/badge/Coverage-80%25-brightgreen.svg)](./services)
[![Monitoring](https://img.shields.io/badge/Monitoring-Prometheus%2FGrafana-orange.svg)](./k8s/monitoring)
[![Infrastructure](https://img.shields.io/badge/Infrastructure-Terraform%20%2B%20Ansible-purple.svg)](./infrastructure)

Production-grade Kahoot clone với microservices architecture, automated testing, monitoring, và CI/CD pipeline được tối ưu hoàn toàn.

## Điểm Nổi Bật

### Priority 1 - Hoàn Thành 100%
- **Testing**: 80% coverage với Jest + Supertest
- **Monitoring**: Prometheus + Grafana dashboards
- **Backup**: Automated daily MongoDB backups
- **Secrets**: K8s encrypted secrets (không hardcode)

### Production Features
- Production-grade error handling
- Structured logging với Winston
- Input validation & sanitization
- Security (Helmet, rate limiting, CORS)
- Circuit breaker cho service calls
- Health checks cho K8s probes

### Performance Optimizations
- Jenkins CI/CD: 52% nhanh hơn (parallelization)
- Terraform: 47% nhanh hơn (20-concurrent)
- Docker multi-stage builds
- Resource-optimized (Free Tier compatible)

## Mục Lục

- [Kiến Trúc](#-kiến-trúc)
- [Quick Start](#-quick-start)
- [Production Deployment](#-production-deployment)
- [Testing](#-testing-priority-11)
- [Monitoring](#-monitoring-priority-12)
- [Backup](#-backup-priority-13)
- [Secrets Management](#-secrets-management-priority-14)
- [Project Structure](#-project-structure)

## Kiến Trúc

### Microservices Overview
```
Frontend (React) → API Gateway → [ Auth | User | Quiz | Game | Analytics ]
                                              ↓
                                        MongoDB + Backups
```

### Chi Tiết Luồng Dữ Liệu

```
┌─────────────────────────────────────────────────────────────────────┐
│ CLIENT (Browser/Mobile) │
└──────────────────────────┬──────────────────────────────────────────┘
                           │
                           │ HTTP/HTTPS (Port 30000)
                           │ WebSocket (Port 30003)
                           ▼
┌─────────────────────────────────────────────────────────────────────┐
│ FRONTEND (React SPA) - NodePort 30006 │
│ • Dynamic Config Injection (window._env_) │
│ • API_BASE_URL: http://<master-ip>:30000 │
│ • SOCKET_URL: http://<master-ip>:30003 │
│ • JWT Token Storage (localStorage) │
└──────────────────────────┬──────────────────────────────────────────┘
                           │
                           │ REST API Calls
                           ▼
┌─────────────────────────────────────────────────────────────────────┐
│ API GATEWAY - Port 3000 (NodePort 30000) │
│ • Request Routing & Load Balancing │
│ • JWT Token Verification (authMiddleware) │
│ • Rate Limiting & CORS │
│ Routes: │
│ /api/auth/* → auth-service:3001 │
│ /api/user/* → user-service:3002 │
│ /api/quiz/* → quiz-service:3004 │
│ /api/game/* → game-service:3003 │
│ /api/analytics/* → analytics-service:3005 │
└────────┬──────────┬──────────┬──────────┬──────────┬───────────────┘
         │ │ │ │ │
    ┌────▼────┐┌───▼────┐┌────▼────┐┌───▼────┐┌────▼─────┐
    │ Auth ││ User ││ Quiz ││ Game ││ Analytics│
    │ Service ││ Service││ Service ││ Service││ Service │
    │ :3001 ││ :3002 ││ :3004 ││ :3003 ││ :3005 │
    └────┬────┘└───┬────┘└────┬────┘└───┬────┘└────┬─────┘
         │ │ │ │ │
         │ │ MongoDB Atlas (Cloud Database) │
         └──────────┴──────────┴──────────────────────┘
                           │
              ┌────────────┴────────────┐
              │ MongoDB Atlas Cluster │
              │ • Managed Cloud Service│
              │ • Auto Backups & Scaling│
              │ • 99.995% SLA │
              └─────────────────────────┘
```

### Component Deployment & Management

#### **1. Infrastructure Layer (AWS EC2)**
| **Jenkin Server** | EC2 c7i-flex.large | Terraform | Jenkin, Nx , Parallel, ....|
| **Master Node** | EC2 c7i-flex.large | Terraform | K8s control plane, SonarQube |
| **Worker Node 1** | EC2 c7i-flex.large | Terraform | Application pods, Monitoring |
| **Worker Node 2** | EC2 c7i-flex.large | Terraform | Application pods, Load balancing |

**Server IP Addresses** (Example from deployment):
- **Jenkins Server**: 54.89.123.45 (Separate EC2 - CI/CD only)
- **K8s Master**: 98.84.105.168 (Control plane only - NO app workloads)
- **Worker 1**: 34.200.233.56 (Apps + SonarQube)
- **Worker 2**: 44.198.175.214 (Apps + Monitoring)

**Pod Distribution Strategy**:
```yaml
# Jenkins Server (54.89.123.45) - Separate EC2 Instance
├── jenkins (Docker container, port 8080)
├── docker daemon (for building images)
├── kubectl (connected to K8s cluster)
└── aws-cli (for ECR push)

# K8s Master Node (98.84.105.168) - Control Plane Only
├── kube-apiserver
├── kube-controller-manager
├── kube-scheduler
├── etcd
└── coredns

# Worker Node 1 (34.200.233.56)
├── kahoot-clone namespace:
│ ├── auth-service (1 replica)
│ ├── user-service (1 replica)
│ ├── quiz-service (1 replica)
│ ├── game-service (1 replica with sessionAffinity)
│ ├── analytics-service (1 replica)
│ └── gateway (1 replica)
│
├── monitoring namespace:
│ ├── prometheus (1 replica)
│ └── grafana (1 replica)
└── sonarqube (NodePort 30900) - Quality Gate

# Worker Node 2 (44.198.175.214)
├── kahoot-clone namespace:
│ ├── auth-service (1 replica)
│ ├── user-service (1 replica)
│ ├── quiz-service (1 replica)
│ ├── game-service (1 replica with sessionAffinity)
│ ├── analytics-service (1 replica)
│ ├── gateway (1 replica)
│ └── frontend (1 replica)
└── monitoring namespace:
    ├── prometheus (1 replica)
    └── grafana (1 replica)
```

**Pod Anti-Affinity Rules**:
- Each service has 2 replicas distributed across both workers
- No two replicas of the same service run on the same node
- Master node has taint `node-role.kubernetes.io/control-plane:NoSchedule`
- Application pods require `node-role=backend` or `node-role=frontend` labels

**Verification Commands**:
```bash
# Check which pods are on which nodes
kubectl get pods -n kahoot-clone -o wide

# Example output:
# NAME READY NODE IP
# auth-service-xxx 1/1 34.200.233.56 10.244.1.10
# auth-service-yyy 1/1 44.198.175.214 10.244.2.10
# game-service-xxx 1/1 34.200.233.56 10.244.1.11
# game-service-yyy 1/1 44.198.175.214 10.244.2.11

# Check node labels
kubectl get nodes --show-labels

# Check master node taints (prevents app scheduling)
kubectl describe node 98.84.105.168 | grep Taints
# Output: Taints: node-role.kubernetes.io/control-plane:NoSchedule
```

**Service Endpoint Distribution**:
| Service | Type | Port/NodePort | Access URL |
|---------|------|---------------|------------|
| **Jenkins** | Standalone | 8080 | http://54.89.123.45:8080 |
| frontend | NodePort | 30001 | http://<master-ip>:30001 |
| gateway | NodePort | 30000 | http://<master-ip>:30000 |
| auth-service | ClusterIP | 3001 | Internal only (via gateway) |
| user-service | ClusterIP | 3002 | Internal only (via gateway) |
| quiz-service | ClusterIP | 3004 | Internal only (via gateway) |
| game-service | ClusterIP | 3003 | Internal + **sessionAffinity: ClientIP** |
| analytics-service | ClusterIP | 3005 | Internal only (via gateway) |
| prometheus | NodePort | 30909 | http://<worker-ip>:30909 |
| grafana | NodePort | 30300 | http://<worker-ip>:30300 |
| sonarqube | NodePort | 30900 | http://<worker-ip>:30900 |

**Why sessionAffinity for game-service?**
- Socket.IO requires persistent connection to same pod
- ClientIP affinity ensures same client always connects to same pod
- Timeout: 10800 seconds (3 hours)
- Prevents session mismatch errors (400 Bad Request)

**Provisioning Tool**: Terraform
```powershell
terraform/
├── providers.tf # AWS provider config
├── vpc.tf # Network: VPC, Subnets, IGW
├── security-groups.tf # Firewall rules (30000-30999, 22, 80, 443, 8080)
├── ec2.tf # 3 K8s EC2 instances (master + 2 workers)
├── jenkins-infrastructure.tf # Separate Jenkins EC2 (t3.medium)
├── user-data.sh # K8s installation script
└── outputs.tf # IP addresses (jenkins_ip, master_ip, worker_ips)
```

**Infrastructure Isolation**:
- **Jenkins Server**: Dedicated EC2 for CI/CD, not part of K8s cluster
  - Connects to K8s via kubectl with kubeconfig
  - Has Docker daemon for building images
  - Pushes to AWS ECR, triggers K8s deployments
- **K8s Cluster**: 3-node dedicated cluster for application workloads
  - Master: Control plane only (no app pods)
  - Workers: Application services + monitoring

**Configuration Management**: Ansible (WSL-based)
```yaml
infrastructure/ansible/
├── inventory/hosts # k8s_master, k8s_workers groups
├── playbooks/
│ ├── deploy-monitoring.yml # Prometheus + Grafana
│ ├── configure-k8s.yml # Cluster setup
│ └── deploy-secrets.yml # Secrets provisioning
└── roles/
    ├── prometheus/
    ├── grafana/
    └── backup/
```

#### **2. Kubernetes Layer (Orchestration)**
| Namespace | Components | NodePort Services | Replicas | Deployed On |
|-----------|-----------|-------------------|----------|-------------|
| **kahoot-clone** | All microservices + Gateway + Frontend | 30000-30005 | 2 per service | Workers only |
| **monitoring** | Prometheus, Grafana | 30909, 30300 | 2 | Workers only |
| **sonarqube** | SonarQube Server | 30900 | 1 | Worker 1 |

**Note**: Jenkins runs on separate EC2 instance (NOT in Kubernetes)

**Deployment Files**:
```yaml
k8s/
├── namespace.yaml
├── configmap.yaml # Environment configs
├── secrets.yaml.example # JWT_SECRET, MONGO_URI, EMAIL credentials
├── frontend-deployment.yaml # React app (1 replicas)
├── gateway-deployment.yaml # API Gateway (2 replicas)
└── services/
    ├── auth-deployment.yaml # 2 replicas
    ├── user-deployment.yaml # 2 replicas
    ├── quiz-deployment.yaml # 2 replicas
    ├── game-deployment.yaml # 2 replicas, sessionAffinity: ClientIP
    └── analytics-deployment.yaml # 2 replicas
```

**Management Tool**: kubectl
```bash
# Deploy to cluster
kubectl apply -f k8s/
kubectl get pods -n kahoot-clone -o wide

# Scale replicas
kubectl scale deployment auth-service --replicas=3 -n kahoot-clone

# View logs
kubectl logs -f deployment/gateway -n kahoot-clone
```

#### **3. CI/CD Pipeline (Jenkins)**
**Location**: Separate EC2 Instance (http://54.89.123.45:8080)

**Infrastructure**:
- **Instance Type**: AWS EC2 t3.medium (2 vCPU, 4GB RAM)
- **NOT part of K8s cluster** - standalone CI/CD server
- **Components**:
  - Jenkins 2.426 (Docker container or systemd service)
  - Docker daemon (for building application images)
  - kubectl CLI (connected to K8s master via kubeconfig)
  - AWS CLI (for ECR authentication and push)
  - SonarScanner CLI 5.0.1.3006 (code quality analysis)

**Connection to K8s**:
```bash
# Jenkins uses kubeconfig to connect to K8s master
kubectl --kubeconfig=/var/jenkins/.kube/config apply -f k8s/
# Connects to: K8s Master API (https://98.84.105.168:6443)
```

**Pipeline Stages** (Jenkinsfile):
```groovy
1. Checkout → Git clone from GitHub
2. Build Services → Parallel: auth, user, quiz, game, analytics, gateway
3. Build Frontend → React build with nginx
4. Push to ECR → AWS ECR (730335595983.dkr.ecr.us-east-1.amazonaws.com)
5. SonarQube Analysis → Code quality scan (http://34.200.233.56:30900)
6. Deploy to K8s → kubectl apply + rollout restart
7. Health Check → Verify pod readiness
```

**Trigger**: GitHub Webhook (automatic on push to main branch)

**Tools Used**:
- **Build**: Docker multi-stage builds
- **Registry**: AWS ECR (Elastic Container Registry)
- **Scanner**: SonarScanner CLI 5.0.1.3006 (Java 17)
- **Deploy**: kubectl via Jenkins K8s plugin

#### **4. Monitoring & Observability**
**Location**: Worker Nodes (monitoring namespace)

**Prometheus** (http://<master-ip>:30909)
- **Scrape Targets**: All services expose /metrics endpoint
- **Retention**: 15 days
- **Scrape Interval**: 15 seconds
- **Configuration**:
```yaml
scrape_configs:
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
        namespaces:
          names: [kahoot-clone, sonarqube, monitoring]
```

**Grafana** (http://<master-ip>:30300, admin/Kahoot@2025)
- **Datasource**: Prometheus (auto-provisioned)
- **Dashboards**: Kubernetes cluster metrics, custom app metrics
- **Alerts**: Configured via Prometheus Alertmanager

**Deployment**: Ansible Playbook
```bash
# Deploy monitoring stack
wsl ansible-playbook ./infrastructure/ansible/playbooks/deploy-monitoring.yml
```

#### **5. Database Layer (MongoDB Atlas)**
**Cloud-Managed Database Service**

**Why MongoDB Atlas?**
- **Fully Managed**: No need to manage MongoDB pods, storage, or backups in K8s
- **High Availability**: Built-in replication across multiple availability zones
- **Auto Scaling**: Automatically scales storage and compute based on load
- **Automated Backups**: Continuous backups with point-in-time recovery
- **Security**: Encryption at rest and in transit, network isolation
- **Performance**: Optimized for cloud with auto-indexing recommendations
- **Cost Effective**: Free tier (512MB) for development, pay-as-you-go for production

**Cluster Configuration**:

| Tier | vCPUs | RAM | Storage | Price |
|------|-------|-----|---------|-------|
| **Free (M0)** | Shared | 512MB | 5GB | $0/month |
| **Dev (M10)** | 2 | 2GB | 10GB | ~$57/month |
| **Prod (M30)** | 8 | 8GB | 40GB | ~$380/month |

**Connection Setup**:
```yaml
# K8s Secret for MongoDB Atlas connection
apiVersion: v1
kind: Secret
metadata:
  name: mongodb-atlas-secret
  namespace: kahoot-clone
type: Opaque
data:
  # Format: mongodb+srv://<username>:<password>@cluster0.xxxxx.mongodb.net/<database>?retryWrites=true&w=majority
  auth-service-uri: bW9uZ29kYitzcnY6Ly8uLi4=
  user-service-uri: bW9uZ29kYitzcnY6Ly8uLi4=
  quiz-service-uri: bW9uZ29kYitzcnY6Ly8uLi4=
  game-service-uri: bW9uZ29kYitzcnY6Ly8uLi4=
  analytics-service-uri: bW9uZ29kYitzcnY6Ly8uLi4=
```

**Database Organization**:
- **Single Cluster**: One MongoDB Atlas cluster serves all microservices
- **Database per Service**: Each service has its own database (auth_db, user_db, quiz_db, game_db, analytics_db)
- **Network Access**: Whitelisted IPs from AWS EC2 worker nodes

**Backup Strategy**:
- **Automated**: MongoDB Atlas continuous backups (default)
- **Retention**: 7-day retention for free tier, configurable for paid tiers
- **Point-in-Time Recovery**: Available on M10+ clusters
- **No K8s CronJobs needed**: Atlas handles all backup operations

**Access Atlas Dashboard**:
```powershell
# MongoDB Atlas URL
start "https://cloud.mongodb.com"

# View connection strings, metrics, backups
# Project: kahoot-clone
# Cluster: kahoot-cluster-0
```

### Tools & Technologies Stack

#### **Frontend**
- **Framework**: React 18.2.0
- **Routing**: React Router v6
- **State**: React Hooks (useState, useEffect)
- **Real-time**: Socket.IO Client 4.5
- **Icons**: React Icons (Fi)
- **HTTP Client**: Fetch API
- **Build**: Create React App → nginx:alpine

#### **Backend Services**
- **Runtime**: Node.js 18-alpine
- **Framework**: Express.js 4.18
- **Database ODM**: Mongoose 7.0
- **Authentication**: jsonwebtoken 9.0, bcryptjs 2.4
- **Validation**: express-validator
- **Email**: Nodemailer (Gmail SMTP)
- **Real-time**: Socket.IO 4.5
- **Security**: Helmet, express-rate-limit, cors
- **Logging**: Winston 3.8
- **Testing**: Jest 29.7, Supertest 6.3

#### **Infrastructure & DevOps**
- **Container**: Docker 24.0, Docker Compose 3.8
- **Orchestration**: Kubernetes 1.28.15
- **IaC**: Terraform 1.5+ (AWS provider)
- **Configuration**: Ansible 2.14 (WSL)
- **CI/CD**: Jenkins 2.426 (Pipeline as Code)
- **Code Quality**: SonarQube 10.4.1 Community Edition
- **Container Registry**: AWS ECR
- **Monitoring**: Prometheus 2.48, Grafana 10.2.3
- **Cloud**: AWS EC2 (c7i-flex.large)

#### **External Services**
- **Email**: Gmail SMTP (phanvantai7913@gmail.com)
- **Version Control**: GitHub (Webhook integration)
- **DNS/Load Balancer**: NodePort services (30000-30999)

### Data Flow Examples

#### **1. User Registration with OTP Verification**
```
Browser → POST /api/auth/register
   ↓
Gateway → auth-service:3001/register
   ↓
auth-service:
   1. Validate input (email, password, username)
   2. Hash password (bcryptjs)
   3. Generate 6-digit OTP code
   4. Save to MongoDB (isVerified: false)
   5. Send OTP email via Nodemailer
   ↓
← Response: { message: "OTP sent to email" }

Browser → POST /api/auth/verify-otp { email, otp }
   ↓
Gateway → auth-service:3001/verify-otp
   ↓
auth-service:
   1. Find user by email
   2. Verify OTP code & expiry
   3. Set isVerified: true
   4. Generate JWT token (userId, email, username)
   ↓
← Response: { token: "eyJhbGc...", user: {...} }

Browser stores token in localStorage
```

#### **2. Real-time Game Session**
```
Host creates game:
Browser → POST /api/game/games { quizId, hostId }
   ↓
Gateway → game-service:3003/games
   ↓
game-service:
   1. Generate 6-digit PIN
   2. Create game session in MongoDB
   3. Initialize Socket.IO room
   ↓
← Response: { pin: "123456", gameId: "..." }

Players join:
Browser → WebSocket connect to game-service:30003
   ↓
socket.emit('join-game', { pin, nickname })
   ↓
game-service (sessionAffinity: ClientIP):
   1. Validate PIN
   2. Add player to game.players[]
   3. Broadcast to room: 'player-joined'
   ↓
All clients ← socket.on('player-joined', playerData)

Host starts game:
socket.emit('start-game')
   ↓
game-service:
   1. Fetch quiz questions
   2. Emit 'question' event with timer
   ↓
All clients ← socket.on('question', questionData)

Player answers:
socket.emit('answer', { playerId, answer, timeUsed })
   ↓
game-service:
   1. Calculate points (1000 * timeBonus * correctness)
   2. Update player score
   3. Emit 'answer-revealed' when all answered/timeout
   ↓
All clients ← socket.on('answer-revealed', correctAnswer)
```

#### **3. Monitoring Data Collection**
```
Every 15 seconds:
Prometheus → HTTP GET /metrics (all services)
   ↓
Services return metrics (text/plain):
   http_requests_total{method="GET",route="/api/user/profile",status="200"} 143
   http_request_duration_seconds_bucket{le="0.1"} 120
   active_users_total 42
   ↓
Prometheus stores time-series data
   ↓
Grafana queries Prometheus:
   Query: rate(http_requests_total[5m])
   ↓
← Dashboard visualization (graphs, gauges)
```

### Infrastructure
- **Kubernetes**: 3 nodes (1 master + 2 workers)
- **Instance**: c7i-flex.large (2 vCPU, 4GB RAM/node)
- **Monitoring**: Prometheus:30909, Grafana:30300
- **CI/CD**: Jenkins:30800 với GitHub Webhook
- **Code Quality**: SonarQube:30900
- **IaC**: Terraform (parallelization -parallelism=20)
- **Config Mgmt**: Ansible (WSL-based playbooks)

## Quick Start

### Prerequisites
- **Docker Desktop**: Container runtime
- **WSL2**: Required for Ansible (Ubuntu recommended)
- **AWS CLI**: Configured with credentials
- **kubectl**: Kubernetes command-line tool
- **Terraform**: Infrastructure as Code
- **Git**: Version control

### 1. Clone & Setup

```powershell
git clone https://github.com/yourusername/kahoot-clone.git
cd kahoot-clone

# Install WSL2 (if not installed)
wsl --install -d Ubuntu

# Configure AWS credentials
aws configure
# Enter: Access Key, Secret Key, Region (us-east-1), Output (json)
```

### 2. Local Development (Docker Compose)

```powershell
# Setup environment variables
cp .env.example .env
# Edit .env and change ALL secrets:
# MONGO_URI, JWT_SECRET, EMAIL_USER, EMAIL_PASSWORD

# Start all services locally
docker-compose up -d

# View logs
docker-compose logs -f

# Access
# Frontend: http://localhost:3001
# Gateway: http://localhost:3000
# Prometheus: http://localhost:9090
# Grafana: http://localhost:3000 (admin/admin)
```

### 3. Run Tests Locally

```powershell
# Install dependencies
cd services\auth-service
npm install

# Run tests with coverage
npm test

# Watch mode (auto-rerun on changes)
npm run test:watch

# View coverage report
start coverage\lcov-report\index.html
```
npm run test:watch
```

## Production Deployment

### Phase 1: Provision Infrastructure (Terraform)

```powershell
cd terraform

# Initialize Terraform providers (AWS, Kubernetes)
terraform init

# Review infrastructure plan
terraform plan

# Deploy 3-node Kubernetes cluster to AWS
terraform apply -auto-approve -parallelism=20

# Get cluster info
terraform output

# Example output:
# jenkins_url = "http://54.89.123.45:8080"
# jenkins_public_ip = "54.89.123.45"
# k8s_master_ip = "98.84.105.168"
# sonarqube_url = "http://34.200.233.56:30900"
# worker_ips = ["34.200.233.56", "44.198.175.214"]
```

**What Terraform Creates:**
- 3x EC2 c7i-flex.large instances (1 master + 2 workers)
- VPC with public subnets & Internet Gateway
- Security groups (SSH, K8s API, NodePorts 30000-30999)
- Kubernetes cluster installation via user-data script
- Jenkins master on control plane node

### Phase 2: Configure Cluster (Ansible)

```powershell
# Enter WSL environment
wsl

# Navigate to project (adjust path for WSL)
cd /mnt/d/DevOps_Lab2/DevOps-Kahoot-Clone

# Test connectivity
ansible -i infrastructure/ansible/inventory/hosts k8s_master -m ping

# Deploy monitoring stack (Prometheus + Grafana)
ansible-playbook infrastructure/ansible/playbooks/deploy-monitoring.yml

# Deploy application secrets
ansible-playbook infrastructure/ansible/playbooks/deploy-secrets.yml

# Exit WSL
exit
```

**What Ansible Deploys:**
- Prometheus (2 replicas, NodePort 30909)
- Grafana (2 replicas, NodePort 30300)
- RBAC roles for Prometheus ServiceAccount
- ConfigMaps for datasources & dashboards
- Kubernetes secrets (JWT, MongoDB, Email credentials)

### Phase 3: Setup CI/CD (Jenkins)

```powershell
# Get Jenkins server IP
$JENKINS_IP = (terraform output -raw jenkins_public_ip)

# Get Jenkins admin password
ssh -i "infrastructure/terraform/keys/kahoot-clone-key.pem" ubuntu@$JENKINS_IP `
  "sudo cat /var/lib/jenkins/secrets/initialAdminPassword"

# Access Jenkins
start "http://${JENKINS_IP}:8080"
```

**Jenkins Configuration Steps:**
1. **Unlock Jenkins**: Paste initial admin password
2. **Install Plugins**: Suggested plugins + Pipeline + Kubernetes + Docker
3. **Create Admin User**: Set username/password
4. **Configure Credentials**:
   - GitHub credentials (username + token)
   - SonarQube token (from SonarQube:30900)
   - AWS ECR credentials (Access Key + Secret Key)
   - Kubernetes config (copy from master: `/etc/kubernetes/admin.conf`)
5. **Create Pipeline Job**:
   - New Item → Pipeline
   - Pipeline script from SCM → Git
   - Repository URL: https://github.com/yourusername/kahoot-clone.git
   - Script Path: Jenkinsfile
6. **Configure Webhook**:
   - GitHub Repo → Settings → Webhooks
   - Payload URL: `http://<jenkins-ip>:8080/github-webhook/`
   - Content type: application/json
   - Events: Push events

**Jenkins to K8s Connection**:
```bash
# Copy kubeconfig from K8s master to Jenkins server
scp -i keys/kahoot-clone-key.pem ubuntu@98.84.105.168:/etc/kubernetes/admin.conf \
    ubuntu@54.89.123.45:/var/jenkins/.kube/config

# Jenkins can now deploy to K8s cluster
kubectl --kubeconfig=/var/jenkins/.kube/config get nodes
```

### Phase 4: Setup SonarQube

```powershell
# Access SonarQube
$WORKER1_IP = (terraform output -json worker_ips | ConvertFrom-Json)[0]
start "http://${WORKER1_IP}:30900"
```

**SonarQube Configuration:**
1. **Login**: admin / admin (change on first login)
2. **Create Project**: Manual → kahoot-clone → Locally
3. **Generate Token**: Copy and save token
4. **Add to Jenkins**:
   - Jenkins → Credentials → Add Secret Text
   - ID: `sonarqube-token`
   - Secret: Paste SonarQube token

### Phase 5: Build & Deploy Application

```powershell
# Create Kubernetes secrets
cd k8s

# Copy secrets template
cp secrets.yaml.example secrets.yaml

# Edit secrets (encode values in base64)
# Example: echo -n "your-secret" | base64
notepad secrets.yaml

# Apply secrets
kubectl create namespace kahoot-clone
kubectl apply -f secrets.yaml

# Trigger Jenkins pipeline (or push to GitHub)
# Jenkins will automatically:
# 1. Build Docker images for all services
# 2. Run SonarQube code analysis
# 3. Push images to AWS ECR
# 4. Deploy to Kubernetes cluster
# 5. Verify health checks
```

### Phase 6: Verify Deployment

```powershell
# Check all pods are running
kubectl get pods -n kahoot-clone

# Expected output (2 replicas per service):
# NAME READY STATUS RESTARTS AGE
# auth-service-xxx 1/1 Running 0 5m
# user-service-xxx 1/1 Running 0 5m
# quiz-service-xxx 1/1 Running 0 5m
# game-service-xxx 1/1 Running 0 5m
# analytics-service-xxx 1/1 Running 0 5m
# gateway-xxx 1/1 Running 0 5m
# frontend-xxx 1/1 Running 0 5m

# Check services
kubectl get svc -n kahoot-clone

# Get server IPs
$JENKINS_IP = (terraform output -raw jenkins_public_ip)
$MASTER_IP = (terraform output -raw k8s_master_ip)
$WORKER1_IP = (terraform output -json worker_ips | ConvertFrom-Json)[0]

# Access application
Write-Host "`n Application URLs:"
Write-Host "Jenkins: http://${JENKINS_IP}:8080"
Write-Host "Frontend: http://${MASTER_IP}:30001"
Write-Host "Gateway API: http://${MASTER_IP}:30000"
Write-Host "Prometheus: http://${MASTER_IP}:30909"
Write-Host "Grafana: http://${MASTER_IP}:30300 (admin/Kahoot@2025)"
Write-Host "SonarQube: http://${WORKER1_IP}:30900"

# Test health endpoint
Invoke-WebRequest -Uri "http://${MASTER_IP}:30000/health"
```

### Phase 7: Monitor & Maintain

```powershell
# View logs
kubectl logs -f deployment/auth-service -n kahoot-clone

# Scale services
kubectl scale deployment user-service --replicas=3 -n kahoot-clone

# Update deployment (after code change)
kubectl rollout restart deployment/quiz-service -n kahoot-clone

# View resource usage
kubectl top nodes
kubectl top pods -n kahoot-clone

# Access Grafana dashboards
start "http://${MASTER_IP}:30300"
# Login: admin / Kahoot@2025
# Navigate to Dashboards → Kubernetes Cluster Monitoring
```

### Troubleshooting Commands

```powershell
# Check pod status
kubectl describe pod <pod-name> -n kahoot-clone

# View recent events
kubectl get events -n kahoot-clone --sort-by='.lastTimestamp'

# Exec into pod for debugging
kubectl exec -it deployment/auth-service -n kahoot-clone -- /bin/sh

# Check service endpoints
kubectl get endpoints -n kahoot-clone

# View ConfigMaps
kubectl get configmap -n kahoot-clone

# Test DNS resolution
kubectl run -it --rm debug --image=busybox --restart=Never -- nslookup gateway.kahoot-clone.svc.cluster.local
```

## Testing (Priority 1.1)

### Test Coverage Target: 80%

**Test Suites:**
- `auth-service/tests/auth.routes.test.js` - Auth flows
- `user-service/tests/achievements.test.js` - User features
- `quiz-service/tests/quiz.routes.test.js` - Quiz CRUD
- `game-service/tests/game.routes.test.js` - Game sessions
- `analytics-service/tests/analytics.routes.test.js` - Analytics
- `shared/tests/errorHandler.test.js` - Middleware

### Run Tests

```powershell
# All services
cd services\auth-service && npm test
cd services\user-service && npm test
cd services\quiz-service && npm test

# With coverage report
npm test -- --coverage

# View coverage
# Open: services\<service>\coverage\index.html
```

### Test Configuration

- **Framework**: Jest 29.7
- **HTTP Testing**: Supertest 6.3
- **DB Mocking**: MongoDB Memory Server 9.1
- **Coverage Thresholds**: 80% (branches, functions, lines, statements)

## Monitoring (Priority 1.2)

### Prometheus + Grafana Stack

**Metrics Tracked:**
- HTTP request rate & duration (histogram)
- Error rates (4xx, 5xx counters)
- Active users & connections (gauge)
- CPU, Memory, Network usage
- Database connection pool

### Access Dashboards

```
Prometheus: http://<master-ip>:30090
Grafana: http://<master-ip>:30300
  Username: admin
  Password: admin123
```

### Prometheus Queries

```promql
# Request rate per service
rate(http_requests_total[5m])

# Error rate
rate(http_errors_total[5m])

# P95 response time
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

# Active users
active_users_total
```

### Custom Metrics in Code

```javascript
const { prometheusMiddleware, metricsHandler } = require('../shared/middleware/prometheus');

app.use(prometheusMiddleware('service-name'));
app.get('/metrics', metricsHandler);
```

## Backup (MongoDB Atlas Managed)

### Automated Cloud Backups

**MongoDB Atlas Backup Features:**
- **Continuous Backups**: Automatic snapshots every 6 hours (M10+ clusters)
- **Point-in-Time Recovery**: Restore to any point within retention window
- **Retention**: 7 days (free), configurable up to 365 days (paid)
- **Cross-Region**: Optional backup to different AWS region
- **Encryption**: All backups encrypted at rest

### Access Backup Dashboard

```powershell
# Login to MongoDB Atlas
start "https://cloud.mongodb.com"

# Navigate to: Clusters → kahoot-cluster-0 → Backup
# View: Snapshots, Scheduled snapshots, Restore options
```

### Restore Operations

**Via Atlas Dashboard:**
1. Go to Clusters → Backup tab
2. Select snapshot or point-in-time
3. Choose restore method:
   - **Automated Restore**: Creates new cluster with data
   - **Download**: Download backup files locally
   - **Query**: Query backup data without restoring

**Example Restore via Atlas CLI:**
```powershell
# Install Atlas CLI
choco install mongodb-atlas-cli

# Login
atlas auth login

# List available backups
atlas backups snapshots list kahoot-cluster-0

# Restore snapshot to new cluster
atlas backups restores start --clusterName kahoot-cluster-0 `
  --snapshotId <snapshot-id> `
  --targetClusterName kahoot-restore
```

### No K8s Backup Management Needed

 **Benefits over self-managed MongoDB**:
- No CronJob configuration required
- No storage management for backups
- No manual restore scripts
- Automated backup verification
- Built-in monitoring and alerting

## Secrets Management (Priority 1.4)

### Kubernetes Encrypted Secrets

**Secrets Managed:**
- MongoDB credentials
- JWT signing keys
- API keys (SendGrid, AWS)
- Grafana admin password
- Encryption keys

### Setup Process

```powershell
# 1. Create .env from template
cp .env.example .env

# 2. Edit .env với secure values
# Generate secure secrets:
openssl rand -base64 64 # For JWT_SECRET
openssl rand -base64 32 # For ENCRYPTION_KEY

# 3. Create K8s secrets
.\setup-secrets.ps1

# 4. Deploy to cluster
kubectl apply -f k8s\secrets\mongodb-secret.yaml
kubectl apply -f k8s\secrets\jwt-secret.yaml
```

### Verify Secrets

```powershell
# List secrets
kubectl get secrets -n kahoot-app

# Describe secret (values hidden)
kubectl describe secret mongodb-secret -n kahoot-app

# Verify encryption
kubectl get secret mongodb-secret -n kahoot-app -o yaml
```

### Security Best Practices

- No hardcoded secrets in code
- .env file in .gitignore
- Encryption at rest enabled
- Rotate secrets every 90 days
- Use RBAC to restrict access

## Project Structure

```
kahoot-clone/
├── services/
│ ├── shared/ # Production utilities
│ │ ├── middleware/
│ │ │ ├── errorHandler.js # Error handling
│ │ │ ├── validator.js # Input validation
│ │ │ ├── security.js # Rate limiting, CORS
│ │ │ ├── healthCheck.js # Health probes
│ │ │ └── prometheus.js # Metrics collection
│ │ ├── utils/
│ │ │ ├── logger.js # Winston logging
│ │ │ └── serviceClient.js # Circuit breaker
│ │ ├── config/
│ │ │ └── database.js # Connection pooling
│ │ ├── tests/
│ │ │ ├── setup.js # Test environment
│ │ │ └── errorHandler.test.js
│ │ └── jest.config.js # Test config
│ ├── auth-service/
│ │ ├── tests/
│ │ │ └── auth.routes.test.js
│ │ ├── server.js # Production-ready
│ │ └── Dockerfile
│ ├── user-service/
│ ├── quiz-service/
│ ├── game-service/
│ └── analytics-service/
├── k8s/
│ ├── monitoring/
│ │ ├── prometheus-deployment.yaml
│ │ └── grafana-deployment.yaml
│ ├── backup/
│ │ └── mongodb-backup.yaml # CronJob + restore
│ ├── secrets/
│ │ ├── mongodb-secret.yaml
│ │ └── jwt-secret.yaml
│ └── *.yaml # Service deployments
├── terraform/
│ ├── k8s-cluster.tf # 3-node cluster
│ ├── apply-optimized.ps1 # 47% faster
│ └── destroy-optimized.ps1
├── docs/ # Detailed guides
├── Jenkinsfile # Optimized pipeline
├── setup-testing.ps1 # Test setup
├── setup-monitoring.ps1 # Monitoring setup
├── setup-backup.ps1 # Backup setup
├── setup-secrets.ps1 # Secrets setup
├── cleanup-project.ps1 # Clean redundant code
├── .env.example # Environment template
└── README.md # This file
```

## Development

### Code Standards

```javascript
// Error handling
const { asyncHandler } = require('../shared/middleware/errorHandler');

app.post('/api/endpoint', asyncHandler(async (req, res) => {
  // Your code here
}));

// Logging
const logger = require('../shared/utils/logger');
logger.info('Operation successful', { userId, action });

// Validation
const { validateRequest } = require('../shared/middleware/validator');

app.post('/api/endpoint',
  validateRequest(['username', 'email']),
  handler
);
```

### Add New Service

1. Create directory in `services/`
2. Copy `jest.config.js` from `shared/`
3. Add Prometheus middleware
4. Create K8s deployment
5. Add to Jenkinsfile
6. Write tests (maintain 80% coverage)

## Production Readiness

| Category | Status | Score |
|----------|--------|-------|
| Testing | 80% | 20/20 |
| Monitoring | Full stack | 15/15 |
| Backup | Automated | 10/10 |
| Secrets | Encrypted | 10/10 |
| Error Handling | Production | 10/10 |
| Logging | Structured | 10/10 |
| Security | Hardened | 10/10 |
| **TOTAL** | **Production Ready** | **85/100** |

## CI/CD Pipeline

**Jenkins Optimized Pipeline (52% faster):**

```
Stage 1: Checkout
Stage 2: Parallel Build (6 services)
Stage 3: Parallel Test (6 services with coverage)
Stage 4: Quality Gate (coverage threshold)
Stage 5: Parallel Docker Build (6 images)
Stage 6: Deploy to K8s
Stage 7: Health Checks
Stage 8: Notifications
```

**Performance:**
- Sequential: ~12 minutes
- Optimized: ~5.8 minutes
- Improvement: 52%

## Documentation

- [PRODUCTION_CHECKLIST.md](./docs/PRODUCTION_CHECKLIST.md) - Quality checklist
- [PARALLELIZATION_GUIDE.md](./docs/PARALLELIZATION_GUIDE.md) - Optimization guide
- [K8S_CLUSTER_GUIDE.md](./docs/K8S_CLUSTER_GUIDE.md) - Kubernetes setup
- [QUICKSTART_JENKINS.md](./QUICKSTART_JENKINS.md) - Jenkins guide

## Contributing

1. Fork repository
2. Create feature branch: `git checkout -b feature/amazing`
3. Write tests (maintain 80% coverage)
4. Commit: `git commit -m 'feat: add feature'`
5. Push: `git push origin feature/amazing`
6. Create Pull Request

## Next Steps (Priority 2-3)

- [ ] Add integration tests (E2E with Cypress)
- [ ] Implement auto-scaling (HPA)
- [ ] Setup centralized logging (ELK stack)
- [ ] Add disaster recovery plan
- [ ] Implement load testing (k6)

## Team

DevOps & Full-Stack Development

---

**Built with using Node.js, React, Kubernetes, and Production-Grade DevOps**

*Test case 1